
## ğŸ§ª Lab 01 â€“ PDF Ingestion with Metadata

### ğŸ¯ Goal

Build a complete ingestion pipeline from raw PDF to searchable vector database using:

* Chroma (vector DB)
* Ollama (embeddings)
* Recursive chunking
* Page-level metadata

---

### ğŸ— Architecture

```
PDF
 â†“
Page Extraction (per page metadata too)
 â†“
Cleaning
 â†“
Chunking (with overlap)
 â†“
Embedding (Ollama)
 â†“
Chroma (id + embedding + metadata)
 â†“
Similarity Query
 â†“
Top-K Retrieval
```

---

### ğŸ“š Key Learnings

1. **RAG is retrieval engineering first**
2. Page-level metadata enables traceability & citations
3. Chunk size and overlap are controllable variables
4. Embeddings are deterministic semantic vectors
5. Vector DB = structured storage + similarity math
6. Retrieval happens before generation

---

### ğŸ“¦ Stored Metadata Example

```json
{
  "source": "sample_pdf",
  "page": 12,
  "chunk_index": 3,
  "chunk_chars": 824,
  "chunk_id": "uuid"
}
```

---

#### Observations from run:

![lab-1-output](data/screenshots/image-1.png)