# ðŸ§  AI RAG Labs

A hands-on, experiment-driven repository for learning and engineering Retrieval-Augmented Generation (RAG) systems using:

* ðŸ§© **Chroma** (Vector Database)
* ðŸ¦™ **Ollama** (Local Embeddings + LLM)
* ðŸ“„ PDF ingestion pipeline
* ðŸ“Š Retrieval benchmarking with measurable metrics

This repo focuses on **retrieval engineering first**, before generation.

---

# ðŸš€ Philosophy

RAG is not:

> PDF â†’ LLM â†’ Answer

RAG is:

```text
Document â†’ Structure â†’ Chunk â†’ Embed â†’ Index â†’ Retrieve â†’ (Then Generate)
```

If retrieval is weak, generation cannot fix it.

This repo isolates and optimizes each stage step-by-step.

---


# ðŸ— Repository Structure
[ðŸ§ª Lab 01 â€“ PDF Ingestion with Metadata](lab01.md)

[ðŸ§ª Lab 02 â€“ Chunking Strategy Benchmark](lab02.md)

[ðŸ§ª Lab 03 â€“ Retrieval Evaluation Harness](lab03.md)


# âš™ï¸ Setup

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Install embedding model in Ollama

```bash
ollama pull nomic-embed-text
```

### 3ï¸âƒ£ Add a PDF

Place your test PDF in:

```
data/raw/sample.pdf
```

---

# ðŸ§  What This Repo Is Really About

This repository is about learning:

* Information Retrieval fundamentals
* Chunking tradeoffs
* Embedding behavior
* Ranking metrics
* Experimental isolation
* Evidence-based optimization

This is not just â€œbuild RAG appâ€.

This is:

> Engineering retrieval systems correctly.
